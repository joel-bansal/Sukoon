{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot install langchain-core, langchain-core==0.1.42, langchain-openai==0.1.3, langchain==0.1.16, langgraph==0.0.39, langgraph==0.0.40, langgraph==0.0.41, langgraph==0.0.42, langgraph==0.0.43, langgraph==0.0.44, langgraph==0.0.45, langgraph==0.0.46, langgraph==0.0.47, langgraph==0.0.48, langgraph==0.0.49, langgraph==0.0.50, langgraph==0.0.51, langgraph==0.0.52, langgraph==0.0.53, langgraph==0.0.54, langgraph==0.0.55, langgraph==0.0.56, langgraph==0.0.57, langgraph==0.0.58, langgraph==0.0.59, langgraph==0.0.60, langgraph==0.0.61, langgraph==0.0.62, langgraph==0.0.63, langgraph==0.0.64, langgraph==0.0.65, langgraph==0.0.66, langgraph==0.0.67, langgraph==0.0.68, langgraph==0.0.69, langgraph==0.1.1, langgraph==0.1.10, langgraph==0.1.11, langgraph==0.1.12, langgraph==0.1.13, langgraph==0.1.14, langgraph==0.1.15, langgraph==0.1.16, langgraph==0.1.17, langgraph==0.1.19, langgraph==0.1.2, langgraph==0.1.3, langgraph==0.1.4, langgraph==0.1.5, langgraph==0.1.6, langgraph==0.1.7, langgraph==0.1.8, langgraph==0.1.9, langgraph==0.2.0, langgraph==0.2.1, langgraph==0.2.10, langgraph==0.2.11, langgraph==0.2.12, langgraph==0.2.13, langgraph==0.2.14, langgraph==0.2.15, langgraph==0.2.16, langgraph==0.2.17, langgraph==0.2.18, langgraph==0.2.19, langgraph==0.2.2, langgraph==0.2.20, langgraph==0.2.21, langgraph==0.2.22, langgraph==0.2.23, langgraph==0.2.24, langgraph==0.2.25, langgraph==0.2.26, langgraph==0.2.27, langgraph==0.2.28, langgraph==0.2.3, langgraph==0.2.32, langgraph==0.2.33, langgraph==0.2.34, langgraph==0.2.35, langgraph==0.2.36, langgraph==0.2.37, langgraph==0.2.38, langgraph==0.2.39, langgraph==0.2.4, langgraph==0.2.5, langgraph==0.2.6, langgraph==0.2.7, langgraph==0.2.8 and langgraph==0.2.9 because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install -r requirements.txt\n",
    "# langgraph\n",
    "# langchain-community\n",
    "# langchain-core\n",
    "# langchain-openai\n",
    "# langchain\n",
    "# langgraph-sdk\n",
    "# langgraph-checkpoint-sqlite\n",
    "# langsmith\n",
    "# langchainhub==0.1.15\n",
    "# langchain-openai==0.1.3\n",
    "# langchain==0.1.16\n",
    "# langchain-core==0.1.42\n",
    "# pygraphviz==1.12\n",
    "# llama-index\n",
    "# fastapi\n",
    "# uvicorn\n",
    "\n",
    "!pip install -qU langgraph langchain-community langchain-core langchain-openai langchain langgraph-sdk langgraph-checkpoint-sqlite langsmith langchainhub==0.1.15 langchain-openai==0.1.3 langchain==0.1.16 langchain-core==0.1.42 pygraphviz==1.12 llama-index fastapi uvicorn openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP Enviornment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "\n",
    "# loading env variables \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"Open_AI_Key\"\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, that's correct. I am a language model developed by OpenAI, and you are accessing my capabilities through an API key. This allows you to interact with me and use my features in various applications. If you have any questions or need assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\", temperature=0,\n",
    "    max_tokens=None,\n",
    ")\n",
    "print(llm.invoke(\"you are gpt model only right which im using via a key?\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 1 No CBT/DBT Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='im feeling low', additional_kwargs={}, response_metadata={}, id='87d15a0c-66b0-4482-9baa-2f9176a94884')]}\n",
      "Running suicide prevention agent\n",
      "Sukoon: I'm really sorry to hear that you're feeling this way. Your feelings are important, and I'm here to listen. It's really important to talk to someone who can provide support. Your life matters, and let's get you the support you need right now.\n",
      "\n",
      "Please consider reaching out to a professional who can help. You can contact one of these helplines for immediate support:\n",
      "- iCALL: +919152987821\n",
      "- NIMHANS: +918046110007 or 14416\n",
      "\n",
      "They have trained professionals who can help you work through what you're experiencing. You are not alone, and there are people who care about you and want to help.\n",
      "suicide_agent **********\n",
      "Bot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from typing import Literal, Annotated\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from typing import TypedDict, List\n",
    "from openai import OpenAI\n",
    "import os \n",
    "from langchain_openai import ChatOpenAI\n",
    "import yaml\n",
    "import csv\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# Define the state\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "BOT_USED = \"\"\n",
    "# Load prompts from YAML\n",
    "def load_prompts(file_path='prompts.yaml'):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "prompts = load_prompts()\n",
    "\n",
    "# Initialize OpenAI model\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0.7)\n",
    "\n",
    "# Define prompts for different agents\n",
    "planner_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a planner agent that decides which specialized agent to call based on the user's input. Respond with one of 'suicide_prevention', 'conversational', 'anger_management', 'motivational', or 'mindfulness' based on the user's emotion.\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "conversational_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompts['empathetic_agent_prompt']),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "suicide_prevention_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompts['suicide_prevention_agent_prompt']),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "\n",
    "anger_management_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompts['anger_prevention_agent_prompt']),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "motivational_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompts['motivational_agent_prompt']),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "mindfulness_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompts['mindfulness_agent_prompt']),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "# Define router\n",
    "def route_query(state: State):\n",
    "    print(state)\n",
    "    class RouteQuery(BaseModel):\n",
    "        \"\"\"Route a user query to the most relevant node.\"\"\"\n",
    "        route: Literal[\"conversational\", \"suicide_prevention\", \"anger_management\", \"motivational\", \"mindfulness\"] = Field(\n",
    "            ...,\n",
    "            description=\"Choose the appropriate agent based on the user's emotions.\"\n",
    "        )\n",
    "    \n",
    "    structured_llm_router = model.with_structured_output(RouteQuery)\n",
    "    question_router = planner_prompt | structured_llm_router\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    resp = question_router.invoke({\"input\": last_message})\n",
    "    return resp.route\n",
    "\n",
    "# Define agent functions\n",
    "def run_conversational_agent(state: State):\n",
    "    global BOT_USED  # Declare BOT_USED as global\n",
    "    print(\"Running conversational agent\")\n",
    "    convo_model = conversational_prompt | model\n",
    "    response = convo_model.invoke(state[\"messages\"])\n",
    "    BOT_USED = \"conversational_agent\"  # Assign to global variable\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def run_suicide_prevention_agent(state: State):\n",
    "    global BOT_USED  # Declare BOT_USED as global\n",
    "    print(\"Running suicide prevention agent\")\n",
    "    concern_model = suicide_prevention_prompt | model\n",
    "    response = concern_model.invoke(state[\"messages\"])\n",
    "    BOT_USED = \"suicide_agent\"  # Assign to global variable\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def run_anger_management_agent(state: State):\n",
    "    global BOT_USED  # Declare BOT_USED as global\n",
    "    print(\"Running anger management agent\")\n",
    "    anger_model = anger_management_prompt | model\n",
    "    response = anger_model.invoke(state[\"messages\"])\n",
    "    BOT_USED = \"anger_agent\"  # Assign to global variable\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def run_motivational_agent(state: State):\n",
    "    global BOT_USED  # Declare BOT_USED as global\n",
    "    print(\"Running motivational agent\")\n",
    "    motivation_model = motivational_prompt | model\n",
    "    response = motivation_model.invoke(state[\"messages\"])\n",
    "    BOT_USED = \"motivational_agent\"  # Assign to global variable\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def run_mindfulness_agent(state: State):\n",
    "    global BOT_USED  # Declare BOT_USED as global\n",
    "    print(\"Running mindfulness agent\")\n",
    "    mindfulness_model = mindfulness_prompt | model\n",
    "    response = mindfulness_model.invoke(state[\"messages\"])\n",
    "    BOT_USED = \"mindfulness_agent\"  # Assign to global variable\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Create the graph\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Add nodes for each agent\n",
    "workflow.add_node(\"conversational\", run_conversational_agent)\n",
    "workflow.add_node(\"suicide_prevention\", run_suicide_prevention_agent)\n",
    "workflow.add_node(\"anger_management\", run_anger_management_agent)\n",
    "workflow.add_node(\"motivational\", run_motivational_agent)\n",
    "workflow.add_node(\"mindfulness\", run_mindfulness_agent)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_conditional_edges(\n",
    "    START,\n",
    "    route_query,\n",
    "    {\n",
    "        \"conversational\": \"conversational\",\n",
    "        \"suicide_prevention\": \"suicide_prevention\",\n",
    "        \"anger_management\": \"anger_management\",\n",
    "        \"motivational\": \"motivational\",\n",
    "        \"mindfulness\": \"mindfulness\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"conversational\", END)\n",
    "workflow.add_edge(\"suicide_prevention\", END)\n",
    "workflow.add_edge(\"anger_management\", END)\n",
    "workflow.add_edge(\"motivational\", END)\n",
    "workflow.add_edge(\"mindfulness\", END)\n",
    "\n",
    "# Compile the graph\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "\n",
    "# Function to run a conversation turn\n",
    "def chat(message: str, config: dict):\n",
    "    result = graph.invoke({\"messages\": [HumanMessage(content=message)]}, config=config)\n",
    "    return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "        \n",
    "    # Open a CSV file for writing\n",
    "    with open('chat_responses.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"User Input\", \"Triggered Agent\", \"Response\"])  # Write the header\n",
    "\n",
    "        # i = 0\n",
    "        while True:\n",
    "            user_input = input(\"You: \")\n",
    "            if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "                print(\"Bot: Goodbye!\")\n",
    "                break\n",
    "                \n",
    "            response = chat(user_input, config)\n",
    "            # response = response[\"messages\"].content\n",
    "            response = response['messages'][-1].content\n",
    "            print(f\"Sukoon: {response}\")\n",
    "\n",
    "            # Log the interaction to the CSV\n",
    "            writer.writerow([user_input, BOT_USED, response])  # Write the data\n",
    "            print(BOT_USED,\"**********\")\n",
    "            BOT_USED = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 2 : DBT CBT added to above 5\n",
    "## Mindfulness removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user query :  hello my name is joel\n",
      "Running conversational agent\n",
      "memory :  <langgraph.checkpoint.memory.MemorySaver object at 0x00000164AD6C22D0>\n",
      "Sukoon: I hear you, Joel. It's nice to meet you. How have you been feeling lately? Remember, it's okay to share whatever's on your mind. 😊\n",
      "user query :  my names?\n",
      "Running conversational agent\n",
      "memory :  <langgraph.checkpoint.memory.MemorySaver object at 0x00000164AD6C22D0>\n",
      "Sukoon: I hear you, Joel. It sounds like there might be a bit of confusion. It's completely okay to take your time with things. How can I support you today? 😊\n",
      "user query :  exit\n",
      "Bot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from typing import Literal, Annotated\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from typing import TypedDict, List\n",
    "from openai import OpenAI\n",
    "import os \n",
    "from langchain_openai import ChatOpenAI\n",
    "import yaml\n",
    "# from semantic_router import Route\n",
    "# from transformers import pipeline\n",
    "from typing import Dict\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# Define the state\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Load prompts from YAML\n",
    "def load_prompts(file_path='prompts.yaml'):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "prompts = load_prompts()\n",
    "\n",
    "# Initialize OpenAI model\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0.7)\n",
    "\n",
    "# Define prompts for different agents\n",
    "# planner_prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", \"You are a planner agent that decides which specialized agent to call based on the user's input. Respond with one of 'suicide_prevention', 'conversational', 'anger_management', 'motivational', or 'mindfulness' based on the user's emotion.\"),\n",
    "#     (\"human\", \"{input}\"),\n",
    "# ])\n",
    "\n",
    "planner_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompts['planner_agent_prompt']),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "conversational_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompts['empathetic_agent_prompt']),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "suicide_prevention_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompts['suicide_prevention_agent_prompt']),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "anger_management_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompts['anger_prevention_agent_prompt']),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "motivational_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompts['motivational_agent_prompt']),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "# mindfulness_prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", prompts['mindfulness_agent_prompt']),\n",
    "#     (\"human\", \"{input}\"),\n",
    "# ])\n",
    "\n",
    "dialectical_behavior_therapy_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompts['dbt_agent_prompt']),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "cognitive_behavioral_therapy_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompts['cbt_agent_prompt']),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Define router\n",
    "def route_query(state: State):\n",
    "  \n",
    "    class RouteQuery(BaseModel):\n",
    "        \"\"\"Route a user query to the most relevant node based on the emotional or psychological state identified from the query intent.\"\"\"\n",
    "        \n",
    "        route: Literal[\n",
    "            \"conversational\", \"suicide_prevention\", \"anger_management\", \n",
    "            \"motivational\", \"dialectical_behavior_therapy\", \"cognitive_behavioral_therapy\"\n",
    "        ] = Field(\n",
    "            ...,\n",
    "            description=(\n",
    "                \"Choose the most appropriate agent based on the user's emotional or psychological needs, inferred from their dialogue: \"\n",
    "\n",
    "                \"'conversational' is ideal for users seeking general empathetic interaction, companionship, or simply wishing to engage in casual dialogue. This route aims to provide emotional support through open, non-directive conversation. \\n\"\n",
    "                \"Example: A user says, 'I've been feeling a bit lonely lately. I just need someone to talk to about my day.'\\n\"\n",
    "\n",
    "                \"'suicide_prevention' is critical for users who express thoughts of hopelessness, self-harm, suicidal ideation, or severe emotional distress. This route provides immediate intervention, offering resources and support to de-escalate the crisis. \\n\"\n",
    "                \"Example: A user states, 'I feel like no one would care if I were gone. I don't want to keep going anymore.'\\n\"\n",
    "\n",
    "                \"'anger_management' should be selected for users expressing frustration, irritability, or anger. This route helps the user manage their temper, process their emotions constructively, and reduce the risk of conflict escalation. \\n\"\n",
    "                \"Example: A user vents, 'I'm so mad at my boss! He keeps undermining me, and I'm about to explode.'\\n\"\n",
    "\n",
    "                \"'motivational' is suited for users who feel demotivated, struggle with low self-esteem, or are seeking encouragement to pursue their goals. This route offers positive reinforcement and practical strategies for improving self-worth and maintaining focus. \\n\"\n",
    "                \"Example: A user shares, 'I’ve been feeling stuck. Every time I try to work on my project, I lose motivation. What’s the point of even trying?' \\n\"\n",
    "\n",
    "                \"'dialectical_behavior_therapy' (DBT) should be used for users dealing with intense, fluctuating emotions or feeling emotionally overwhelmed. DBT teaches skills for emotional regulation, distress tolerance, and managing interpersonal relationships. \\n\"\n",
    "                \"Example: A user says, 'One moment I’m okay, but then I’m hit with this overwhelming sadness and anger. I don’t know how to control my emotions.'\\n\"\n",
    "\n",
    "                \"'cognitive_behavioral_therapy' (CBT) is appropriate for users struggling with negative or distorted thinking patterns, self-criticism, or irrational beliefs. CBT helps them reframe unhealthy thoughts into more positive, balanced perspectives. \\n\"\n",
    "                \"Example: A user confides, 'I always mess things up. No matter what I do, I feel like a failure, and it’s hard to think any differently.'\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    structured_llm_router = model.with_structured_output(RouteQuery)\n",
    "    question_router = planner_prompt | structured_llm_router\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    resp = question_router.invoke({\"input\": last_message})\n",
    "    return resp.route\n",
    "\n",
    "# Define agent functions\n",
    "def run_conversational_agent(state: State):\n",
    "    print(\"Running conversational agent\")\n",
    "    convo_model = conversational_prompt | model\n",
    "    response = convo_model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def run_suicide_prevention_agent(state: State):\n",
    "    print(\"Running suicide prevention agent\")\n",
    "    concern_model = suicide_prevention_prompt | model\n",
    "    response = concern_model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def run_anger_management_agent(state: State):\n",
    "    print(\"Running anger management agent\")\n",
    "    anger_model = anger_management_prompt | model\n",
    "    response = anger_model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def run_motivational_agent(state: State):\n",
    "    print(\"Running motivational agent\")\n",
    "    motivation_model = motivational_prompt | model\n",
    "    response = motivation_model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "# def run_mindfulness_agent(state: State):\n",
    "#     print(\"Running mindfulness agent\")\n",
    "#     mindfulness_model = mindfulness_prompt | model\n",
    "#     response = mindfulness_model.invoke(state[\"messages\"])\n",
    "#     return {\"messages\": response}\n",
    "\n",
    "def run_dialectical_behavior_therapy_agent(state: State):\n",
    "    print(\"Running dialectical_behavior_therapy agent\")\n",
    "    dialectical_behavior_therapy_model = dialectical_behavior_therapy_prompt | model\n",
    "    response = dialectical_behavior_therapy_model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def run_cognitive_behavioral_therapy_agent(state: State):\n",
    "    print(\"Running cognitive_behavioral_therapy agent\")\n",
    "    cognitive_behavioral_therapy_model = cognitive_behavioral_therapy_prompt | model\n",
    "    response = cognitive_behavioral_therapy_model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "# Create the graph\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Add nodes for each agent\n",
    "workflow.add_node(\"conversational\", run_conversational_agent)\n",
    "workflow.add_node(\"suicide_prevention\", run_suicide_prevention_agent)\n",
    "workflow.add_node(\"anger_management\", run_anger_management_agent)\n",
    "workflow.add_node(\"motivational\", run_motivational_agent)\n",
    "# workflow.add_node(\"mindfulness\", run_mindfulness_agent)\n",
    "workflow.add_node(\"dialectical_behavior_therapy\", run_dialectical_behavior_therapy_agent)\n",
    "workflow.add_node(\"cognitive_behavioral_therapy\", run_cognitive_behavioral_therapy_agent)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_conditional_edges(\n",
    "    START,\n",
    "    route_query,\n",
    "    {\n",
    "        \"conversational\": \"conversational\",\n",
    "        \"suicide_prevention\": \"suicide_prevention\",\n",
    "        \"anger_management\": \"anger_management\",\n",
    "        \"motivational\": \"motivational\",\n",
    "        # \"mindfulness\": \"mindfulness\",\n",
    "        \"dialectical_behavior_therapy\": \"dialectical_behavior_therapy\",\n",
    "        \"cognitive_behavioral_therapy\": \"cognitive_behavioral_therapy\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"conversational\", END)\n",
    "workflow.add_edge(\"suicide_prevention\", END)\n",
    "workflow.add_edge(\"anger_management\", END)\n",
    "workflow.add_edge(\"motivational\", END)\n",
    "# workflow.add_edge(\"mindfulness\", END)\n",
    "workflow.add_edge(\"dialectical_behavior_therapy\", END)\n",
    "workflow.add_edge(\"cognitive_behavioral_therapy\", END)\n",
    "\n",
    "# Compile the graph\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "\n",
    "\n",
    "# Function to run a conversation turn\n",
    "def chat(message: str, config: dict):\n",
    "    result = graph.invoke({\"messages\": [HumanMessage(content=message)]}, config=config)\n",
    "    return result[\"messages\"][-1]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "    i = 0\n",
    "    while True and i<5:\n",
    "        i+=1\n",
    "        user_input = input(\"You: \")\n",
    "        print(\"user query : \",user_input)\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"Bot: Goodbye!\")\n",
    "            break\n",
    "        response = chat(user_input, config)\n",
    "        print(\"memory : \",memory)\n",
    "        print(\"Sukoon:\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__aenter__', '__aexit__', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_is_protocol', 'aget', 'aget_tuple', 'alist', 'aput', 'aput_writes', 'config_specs', 'get', 'get_next_version', 'get_tuple', 'list', 'put', 'put_writes', 'serde', 'storage', 'writes']\n",
      "<built-in method __dir__ of MemorySaver object at 0x00000164AD60E590>\n",
      "{'serde': <langgraph.checkpoint.serde.jsonplus.JsonPlusSerializer object at 0x00000164ABD4DBD0>, 'storage': defaultdict(<function MemorySaver.__init__.<locals>.<lambda> at 0x00000164AD701800>, {'1': defaultdict(<class 'dict'>, {'': {'1ef93162-1f52-6247-bfff-8666bb816584': (('msgpack', b'\\x86\\xa1v\\x01\\xa2ts\\xd9 2024-10-25T21:14:34.005152+00:00\\xa2id\\xd9$1ef93162-1f52-6247-bfff-8666bb816584\\xaechannel_values\\x81\\xa9__start__\\x81\\xa8messages\\x91\\xc7\\x96\\x05\\x94\\xbdlangchain_core.messages.human\\xacHumanMessage\\x87\\xa7content\\xa8helo idk\\xb1additional_kwargs\\x80\\xb1response_metadata\\x80\\xa4type\\xa5human\\xa4name\\xc0\\xa2id\\xc0\\xa7example\\xc2\\xb3model_validate_json\\xb0channel_versions\\x81\\xa9__start__\\xd9300000000000000000000000000000001.0.7048784477121884\\xadversions_seen\\x81\\xa9__input__\\x80'), ('msgpack', b'\\x84\\xa6source\\xa5input\\xa6writes\\x81\\xa9__start__\\x81\\xa8messages\\x91\\xc7\\x96\\x05\\x94\\xbdlangchain_core.messages.human\\xacHumanMessage\\x87\\xa7content\\xa8helo idk\\xb1additional_kwargs\\x80\\xb1response_metadata\\x80\\xa4type\\xa5human\\xa4name\\xc0\\xa2id\\xc0\\xa7example\\xc2\\xb3model_validate_json\\xa4step\\xff\\xa7parents\\x80'), None), '1ef93162-2747-625b-8000-1945dd6dc46e': (('msgpack', b'\\x86\\xa1v\\x01\\xa2ts\\xd9 2024-10-25T21:14:34.839509+00:00\\xa2id\\xd9$1ef93162-2747-625b-8000-1945dd6dc46e\\xaechannel_values\\x82\\xa8messages\\x91\\xc7\\xbb\\x05\\x94\\xbdlangchain_core.messages.human\\xacHumanMessage\\x87\\xa7content\\xa8helo idk\\xb1additional_kwargs\\x80\\xb1response_metadata\\x80\\xa4type\\xa5human\\xa4name\\xc0\\xa2id\\xd9$7a17fb8d-5ac3-4d61-85a9-572a1d657092\\xa7example\\xc2\\xb3model_validate_json\\xd9+branch:__start__:route_query:conversational\\xa9__start__\\xb0channel_versions\\x83\\xa9__start__\\xd9300000000000000000000000000000002.0.5589996671359524\\xa8messages\\xd9300000000000000000000000000000002.0.7193102403727347\\xd9+branch:__start__:route_query:conversational\\xd9400000000000000000000000000000002.0.31511753512172036\\xadversions_seen\\x82\\xa9__input__\\x80\\xa9__start__\\x81\\xa9__start__\\xd9300000000000000000000000000000001.0.7048784477121884'), ('msgpack', b'\\x84\\xa6source\\xa4loop\\xa6writes\\xc0\\xa4step\\x00\\xa7parents\\x80'), '1ef93162-1f52-6247-bfff-8666bb816584'), '1ef93162-2fa4-6d1c-8001-eb9ef3eee69f': (('msgpack', b\"\\x86\\xa1v\\x01\\xa2ts\\xd9 2024-10-25T21:14:35.715742+00:00\\xa2id\\xd9$1ef93162-2fa4-6d1c-8001-eb9ef3eee69f\\xaechannel_values\\x82\\xa8messages\\x92\\xc7\\xbb\\x05\\x94\\xbdlangchain_core.messages.human\\xacHumanMessage\\x87\\xa7content\\xa8helo idk\\xb1additional_kwargs\\x80\\xb1response_metadata\\x80\\xa4type\\xa5human\\xa4name\\xc0\\xa2id\\xd9$7a17fb8d-5ac3-4d61-85a9-572a1d657092\\xa7example\\xc2\\xb3model_validate_json\\xc8\\x03\\x1e\\x05\\x94\\xbalangchain_core.messages.ai\\xa9AIMessage\\x8a\\xa7content\\xd9\\xb8I hear you, it's tough when things feel uncertain. It's okay not to know everything right now. You're doing your best, and that's what matters. Remember, you're not alone in this. \\xf0\\x9f\\x8c\\xbb\\xb1additional_kwargs\\x81\\xa7refusal\\xc0\\xb1response_metadata\\x85\\xabtoken_usage\\x85\\xb1completion_tokens(\\xadprompt_tokens\\xcd\\x02:\\xactotal_tokens\\xcd\\x02b\\xb9completion_tokens_details\\x82\\xacaudio_tokens\\xc0\\xb0reasoning_tokens\\x00\\xb5prompt_tokens_details\\x82\\xacaudio_tokens\\xc0\\xadcached_tokens\\x00\\xaamodel_name\\xb1gpt-4o-2024-08-06\\xb2system_fingerprint\\xadfp_a7d06e42a7\\xadfinish_reason\\xa4stop\\xa8logprobs\\xc0\\xa4type\\xa2ai\\xa4name\\xc0\\xa2id\\xd9*run-4a69f98b-7815-465a-ae17-726b05b01c82-0\\xa7example\\xc2\\xaatool_calls\\x90\\xb2invalid_tool_calls\\x90\\xaeusage_metadata\\x85\\xacinput_tokens\\xcd\\x02:\\xadoutput_tokens(\\xactotal_tokens\\xcd\\x02b\\xb3input_token_details\\x81\\xaacache_read\\x00\\xb4output_token_details\\x81\\xa9reasoning\\x00\\xb3model_validate_json\\xaeconversational\\xaeconversational\\xb0channel_versions\\x84\\xa9__start__\\xd9300000000000000000000000000000002.0.5589996671359524\\xa8messages\\xd9400000000000000000000000000000003.0.07751770144195491\\xd9+branch:__start__:route_query:conversational\\xd9400000000000000000000000000000003.0.35572839034569537\\xaeconversational\\xd9300000000000000000000000000000003.0.2621650622009183\\xadversions_seen\\x83\\xa9__input__\\x80\\xa9__start__\\x81\\xa9__start__\\xd9300000000000000000000000000000001.0.7048784477121884\\xaeconversational\\x81\\xd9+branch:__start__:route_query:conversational\\xd9400000000000000000000000000000002.0.31511753512172036\"), ('msgpack', b\"\\x84\\xa6source\\xa4loop\\xa6writes\\x81\\xaeconversational\\x81\\xa8messages\\xc8\\x03\\x1e\\x05\\x94\\xbalangchain_core.messages.ai\\xa9AIMessage\\x8a\\xa7content\\xd9\\xb8I hear you, it's tough when things feel uncertain. It's okay not to know everything right now. You're doing your best, and that's what matters. Remember, you're not alone in this. \\xf0\\x9f\\x8c\\xbb\\xb1additional_kwargs\\x81\\xa7refusal\\xc0\\xb1response_metadata\\x85\\xabtoken_usage\\x85\\xb1completion_tokens(\\xadprompt_tokens\\xcd\\x02:\\xactotal_tokens\\xcd\\x02b\\xb9completion_tokens_details\\x82\\xacaudio_tokens\\xc0\\xb0reasoning_tokens\\x00\\xb5prompt_tokens_details\\x82\\xacaudio_tokens\\xc0\\xadcached_tokens\\x00\\xaamodel_name\\xb1gpt-4o-2024-08-06\\xb2system_fingerprint\\xadfp_a7d06e42a7\\xadfinish_reason\\xa4stop\\xa8logprobs\\xc0\\xa4type\\xa2ai\\xa4name\\xc0\\xa2id\\xd9*run-4a69f98b-7815-465a-ae17-726b05b01c82-0\\xa7example\\xc2\\xaatool_calls\\x90\\xb2invalid_tool_calls\\x90\\xaeusage_metadata\\x85\\xacinput_tokens\\xcd\\x02:\\xadoutput_tokens(\\xactotal_tokens\\xcd\\x02b\\xb3input_token_details\\x81\\xaacache_read\\x00\\xb4output_token_details\\x81\\xa9reasoning\\x00\\xb3model_validate_json\\xa4step\\x01\\xa7parents\\x80\"), '1ef93162-2747-625b-8000-1945dd6dc46e')}})}), 'writes': defaultdict(<class 'dict'>, {})}\n",
      "<built-in method __getstate__ of MemorySaver object at 0x00000164AD60E590>\n",
      "<method-wrapper '__getattribute__' of MemorySaver object at 0x00000164AD60E590>\n",
      "<bound method MemorySaver.list of <langgraph.checkpoint.memory.MemorySaver object at 0x00000164AD60E590>>\n"
     ]
    }
   ],
   "source": [
    "print(dir(memory))\n",
    "print(memory.__dir__)\n",
    "print(memory.__dict__)\n",
    "print(memory.__getstate__)\n",
    "print(memory.__getattribute__)\n",
    "print(memory.list)\n",
    "# for message in memory.state.get(\"messages\", []):\n",
    "#     print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Goodbye!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
